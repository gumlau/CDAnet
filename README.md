# CDAnet Workspace

This repository hosts a cleaned-up training and evaluation pipeline for the CDAnet physics-informed super-resolution model, along with data-generation utilities that mirror the configuration used in Hammoud et al. (2022).

## Project Layout

- `train_cdanet.py` – main training script wrapped around the reference UNet3D + ImNet architecture.
- `evaluate_cdanet.py` – quantitative evaluation using saved checkpoints.
- `visualize_results.py` – post-processing and diagnostic plotting for trained models.
- `generate_rb_data.py` – stable synthetic Rayleigh–Bénard (RB) data generator.
- `cdanet/` – torch dataset utilities and auxiliary modules.
- `sourcecodeCDAnet/` – reference implementation used for low-level layers (imported by the main scripts).

## CDAnet Architecture

CDAnet follows the hybrid structure introduced in the paper:

1. **3D UNet Feature Extractor** (`sourcecodeCDAnet/model/unet3d.py`)
   - Input tensor shape: `[batch, channels, T, H, W]` where channels = 4 (`[p, b, u, w]`).
   - Down/upsampling path captures spatio-temporal context on coarse inputs.
   - Output latent grid shape: `[batch, latent_dim, T, H, W]`.

2. **Local Implicit Decoder (ImNet)** (`sourcecodeCDAnet/model/implicit_net.py`)
   - Receives latent features and query coordinates `(t, z, x)` generated by the dataset.
   - Predicts four physical variables at arbitrary high-resolution points.
   - Physics residuals from `get_rb2_pde_layer` regularize predictions via Rayleigh–Bénard equations.

During training, `train_cdanet.py` samples 3D crops, evaluates the implicit decoder on random coordinates, and combines reconstruction and PDE penalties. Inference (visualization/evaluation) walks over full high-resolution coordinate grids using chunking to control memory consumption.

## Rayleigh–Bénard Data Generation

`generate_rb_data.py` creates consolidated HDF5 datasets compatible with CDAnet:

- **Default parameters** reproduce Hammoud et al. (2022):
  - `--n_runs 25` (20 for training, 5 for validation/testing).
  - `--n_samples 200` snapshots per run captured with `--dt 0.1`, covering `t ∈ [25, 45]`.
  - High-resolution grid defaults to `nx = ny = 256` with analytic multi-scale convection features, random plumes, and velocity fields derived from a stream function.
- Output file: `rb2d_ra<Ra>_consolidated.h5` containing channels `[p, b, u, w]` with metadata (`Ra`, `Pr`, `dt`, etc.).
- Optional `--visualize` flag writes a multi-panel overview of the generated dataset.

Quick dataset generation:

```bash
python3 generate_rb_data.py \
    --Ra 1e5 \
    --n_runs 25 \
    --n_samples 200 \
    --dt 0.1 \
    --save_path rb_data_numerical \
    --visualize
```

### RB Data Animation

Create an animation that places low-resolution temperature/velocity (left column) next to their
high-resolution counterparts (right column):

```bash
python3 visualize_rb_data_animation.py \
    --input rb_data_numerical/rb2d_ra1e+05_consolidated.h5 \
    --run 0 \
    --frames 200 \
    --downsample 4 \
    --output rb_animation.mp4
```

The script uses Matplotlib’s `FuncAnimation`; install `ffmpeg` or `imagemagick` locally to export `mp4`/`gif`. Adjust `--quiver_step_high` and `--quiver_step_low` if you want sparser velocity arrows.

## Training

```bash
python3 train_cdanet.py \
    --data_folder ./rb_data_numerical \
    --train_data rb2d_ra1e+05_consolidated.h5 \
    --eval_data rb2d_ra1e+05_consolidated.h5 \
    --epochs 100 \
    --batch_size 1 \
    --n_samp_pts_per_crop 4096 \
    --downsamp_xz 2 \
    --alpha_pde 0.02 \
    --output_folder ./outputs
```

Adjust hyper-parameters based on available compute (e.g., `--batch_size`, `--n_samp_pts_per_crop`, `--alpha_pde`).

## Evaluation & Visualization

```bash
python3 evaluate_cdanet.py --checkpoint ./outputs/checkpoint_best.pth
python3 visualize_results.py --checkpoint ./outputs/checkpoint_best.pth --variable T
python3 quantitative_evaluation.py --checkpoint ./outputs/checkpoint_best.pth --data_dir ./rb_data_numerical
```

- `evaluate_cdanet.py` prints dataset-level metrics (RRMSE, MAE, etc.) and can export logs for additional splits.
- `visualize_results.py` resolves the dataset path automatically, aligns channel order, and renders comparison / temporal plots in `./visualizations/`.
- `quantitative_evaluation.py` now denormalizes predictions, computes detailed statistics, saves diagnostic plots, and exports `detailed_analysis/metrics_summary.json`.

## Requirements

Install dependencies (PyTorch + scientific stack) using the provided list:

```bash
pip install -r requirements.txt
```

For GPU acceleration ensure CUDA-enabled torch binaries are available.

---

This README reflects the streamlined codebase: legacy artifacts have been removed, defaults align with the published experiments, and the documentation highlights the core components needed to generate data, train CDAnet, and analyse results.
